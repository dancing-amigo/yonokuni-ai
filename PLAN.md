# 実装プラン

Yonokuni AI は Python/Gym ベースで 4 色チーム戦ボードゲームの AlphaZero 学習環境とトレーニングパイプラインを構築するプロジェクトです。以下では、仕様確定から環境実装、学習・評価・運用までを詳細なステップに分解します。

## 1. 仕様確定とプロジェクトセットアップ
- [ ] ゲームルール仕様書を作成（初期配置、ターン順、取り方、死に駒判定、中央勝利条件、手番スキップ、終局条件）。
- [ ] Python プロジェクトのベースディレクトリ構成を決定（`yonokuni/`, `tests/`, `configs/`, `scripts/`, `notebooks/` など）。
- [ ] Poetry もしくは pip-tools で依存管理をセットアップ（Gymnasium, numpy, torch, rich, hydra など）。
- [ ] コーディング規約・フォーマット（black, isort, mypy, ruff）を導入し、プリコミットフックを用意。
- [ ] ルール仕様と実装コードを同期するための CHANGELOG/仕様変更テンプレートを準備。

## 2. コアゲームロジック（Python ライブラリ）
- [ ] 盤面・駒・プレイヤー状態を表現するデータ構造を設計（`NamedTuple`/`dataclass`/`numpy arrays`）。
- [ ] 移動検証ロジックを実装（直線移動、途中障害検査、目的地空判定）。
- [ ] 同色サンド取りの判定関数を実装（レイキャスト、同色終端のみ成立、味方異色は壁扱い）。
- [ ] 包囲取りロジックを BFS ベースで実装（手番色以外の連結探索、`can_move` 判定、全員ブロックで捕獲）。
- [ ] 捕獲後の損失数更新と死に駒化処理（閾値到達で盤上駒の `is_dead` フラグ反映）。
- [ ] 中央 4 マス勝利・チーム敗北判定・合法手ゼロ時のスキップ処理を統合。
- [ ] 完全なターン進行関数を構築（移動→捕獲→状態更新→勝敗判定→次手番選択）。
- [ ] 盤面初期化・リセット・合法手列挙・死に駒確認などの API を整備。

## 3. テストと検証
- [ ] 単体テストを作成（移動可否、サンド取り、包囲取り、死に駒処理、中央勝利、スキップ、終局条件）。
- [ ] パラメトリックテストで代表局面（角・辺・中央）を網羅。
- [ ] テストデータベース（YAML/JSON）に典型局面と期待結果を保存し再利用可能にする。
- [ ] 乱択フイジテスト（ランダム合法手で一定ターン進め、例外や非合法状態が出ないことを検証）。
- [ ] ルール仕様とテストケースの対応表を作成し、変更時の影響範囲を可視化。

## 4. Gym 環境 (`YonokuniEnv`)
- [ ] Gymnasium API に準拠したクラスを実装（`reset`, `step`, `render`, `legal_actions`, `close`）。
- [ ] 観測空間を 8 チャンネル盤面（各色 alive/dead フラグ別） + 現在手番/死に駒ワンホット + オプションの補助ベクトルで構築。
- [ ] 行動空間を `MultiDiscrete` あるいは `Discrete(1792)` としてモデル化し、index と (from_row, from_col, direction, distance) の相互変換を実装。
- [ ] 合法手マスクを `step` と `legal_actions` 経由で返却し、MCTS が利用できる形式にする。
- [ ] 終局条件（中央勝利、両色死に駒、手数上限ドロー）と報酬スキーマ（Team A 視点 ±1 / 0）を実装。
- [ ] `render` で ASCII 表示と、後続の可視化フック（matplotlib/pygame 用）を提供。

## 5. ゴールデンテストと同値性保証
- [ ] 仕様ベースの決め打ち行動列（例: 初期から 20 手分）を複数用意し、期待盤面・捕獲・勝敗をスナップショットとして保存。
- [ ] Gym 環境のステップと手計算/仕様スクリプトを比較し、完全一致することを検証。
- [ ] テストを CI に組み込み、ルール変更時の回帰を自動検出。
- [ ] 任意のシードで自己対戦させたログを再生し、同じ乱数シードで再現できることを確認。

## 6. MCTS 実装
- [ ] 盤面ハッシュ（Zobrist 等）を導入し、MCTS ノードの重複を防止。
- [ ] PUCT/Gumbel AlphaZero の探索ループを実装（子ノード選択、展開、バックアップ、温度制御）。
- [ ] Dirichlet ノイズ導入、探索毎の合法手マスク適用、探索統計（visit count, Q 値）蓄積。
- [ ] 4 色プレイに合わせ、手番が進むたびに価値の符号反転/チーム視点変換を行う。
- [ ] 探索並列化（バッチ推論、マルチスレッド/プロセス）を設計。
- [ ] MCTS デバッグ用に探索木の深さ分布・方策エントロピー・勝率推定をロギング。

## 7. ニューラルネットワーク
- [ ] 入力特徴量テンソルを定義（`[batch, channels, 8, 8]` + 補助ベクトル）。
- [ ] Small ResNet（例: 128ch, 10〜12 residual blocks）を構築し、方策ヘッド（1792 ロジット）と価値ヘッド（tanh 出力）を実装。
- [ ] FiLM や加算で補助ベクトルを条件付けする層を追加。
- [ ] TorchScript/ONNX など推論用エクスポートルートを検討。
- [ ] 初期モデル（ランダム or He init）作成、重み保存/読み込みユーティリティを実装。
- [ ] テストで順伝播形状・損失計算・勾配が期待通りであることを確認。

## 8. 自己対戦とデータ収集
- [ ] 自己対戦マネージャを実装（複数ワーカーで Gym 環境を並列起動、MCTS で手を選択）。
- [ ] 温度スケジュール（序盤 τ=1, 以降 τ→0）、探索回数設定（本番/軽量の両方）を構成ファイルで管理。
- [ ] 対局中の `(state, π, z)` をリプレイバッファに記録し、バッファサイズ・サンプリング戦略（均等/優先度）を設計。
- [ ] D4 対称 + 色循環のデータ拡張を実装し、方策ベクトルの再マッピングを保証。
- [ ] 収集データの検証スクリプト（欠損・NaN・異常値チェック、勝率バランス監視）を作成。

## 9. 学習ループ
- [ ] トレーニングスクリプトを実装（Hydra/argparse で設定切り替え可能にする）。
- [ ] 損失関数を `cross_entropy(policy) + mse(value) + λ * L2` とし、λ や勾配クリップなどハイパーパラメータを設定。
- [ ] Optimizer（AdamW）とスケジューラ（Cosine Decay with warmup）を導入。
- [ ] mixed precision / gradient accumulation のオプションを追加。
- [ ] チェックポイント保存（モデル・オプティマイザ・スケジューラ・リプレイバッファ）と自動再開機構を実装。
- [ ] 学習過程のロギング（TensorBoard, wandb, Neptune 等）とメトリクス整理。

## 10. モデル選定と評価
- [ ] 新旧モデルのゲーティングマッチを自動化（固定シードで複数対局、勝率 >55% で昇格）。
- [ ] ルールベース Bot、旧モデル、ランダムプレイヤーとの対戦ベンチマークを定義。
- [ ] 評価メトリクスを記録（勝率、平均手数、中央勝利率、死に駒発生ターン分布、色別勝率）。
- [ ] 重要局面のリプレイ生成（盤面シーケンス、MCTS 訪問分布、ネットワーク出力）を自動化。
- [ ] モデルアーカイブを構築し、昇格モデルのみを本番向けにタグ付け。

## 11. 推論・運用
- [ ] 推論専用ランタイムを実装（軽量 MCTS または方策単独プレイ、バッチ推論対応）。
- [ ] サービス統合向け API（REST/WebSocket/CLI）を定義し、対局サーバや UI への接続方法を整理。
- [ ] モデルのリリースフロー（バージョニング、リリースノート、ロールバック手順）をドキュメント化。
- [ ] 監視項目（推論レイテンシ、勝率ドリフト、MCTS 探索深度など）とアラート閾値を設定。

## 12. インフラと運用自動化
- [ ] コンテナイメージ（Docker）を作成し、学習・自己対戦・評価・推論すべてを統一環境で再現可能にする。
- [ ] 学習ジョブ・評価ジョブをスケジューラ（Kubernetes/Airflow/OSS alternatives）で管理。
- [ ] GPU/CPU リソースの割当ポリシーと、少資源モード（探索回数削減・自己対戦並列数削減）を用意。
- [ ] バックアップとストレージポリシー（モデル, リプレイバッファ, ログ）を策定。

## 13. ドキュメント・ナレッジ共有
- [ ] 仕様・環境・学習パラメータをまとめたリファレンスドキュメントを整備。
- [ ] 自己対戦データ解析や学習結果分析の Jupyter Notebook テンプレートを提供。
- [ ] 新規開発者向けオンボーディングガイドと FAQ を作成。
- [ ] 定期的な技術レビュー・ふりかえりの議事録テンプレートを追加。

このプランに沿って進めることで、Yonokuni AI の Python/Gym 環境と AlphaZero 学習パイプラインを一貫性のある形で構築し、学習〜評価〜運用までを自動化・再現可能な形で完成させることを目指します。
