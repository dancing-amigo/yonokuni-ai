# TensorBoard 指標ガイド

このファイルは自動生成ではなく、指標の意味と読み解き方をまとめたドキュメントです。TensorBoard のグラフと併せて参照し、異常検知やチューニングの判断材料にしてください。

## 1. buffer 系

| 指標名 | 単位・レンジ | 解釈 | 値が示すもの |
| --- | --- | --- | --- |
| `buffer/size` | サンプル数（整数）またはバッファ充足率（0.0〜1.0）※実装依存 | 自己対局やリプレイから集めたサンプルバッファの現在容量。 | 高すぎる場合は古いデータが押し出され最新データ偏重、低すぎる場合は学習が過学習しやすくなる。設定した上限の 60〜90% で推移していれば循環が健康。 |

## 2. self_play / sefl_play 系

| 指標名 | 単位・レンジ | 解釈 | 値の読み方 |
| --- | --- | --- | --- |
| `self_play/average_moves` | ターン数（整数） | 自己対局 1 ゲームあたりの平均手数。 | 上昇はゲームが長期化している兆候。ルール上の最大ターンに近づくと引き分けや停滞が増えている可能性。急減は序盤で勝負が決している/バグで投了している恐れ。 |
| `self_play/center_rate_none` | 0.0〜1.0（割合） | チーム区別「なし (none)」で集計した全体の中央マス占有率。各ターンで中央セル(例: 3×3)に味方駒がある割合。 | 0.5 以上で中央優勢。ゲームデザインに応じて 0.3 未満なら中央軽視、0.8 以上が続くと中央に固執し過ぎて周辺を捨てている可能性。 |
| `sefl_play/center_rate_team_a` | 0.0〜1.0（割合） | チームA（最新モデル）の中央占有率。 | 0.5 を大きく上回れば中央取り合戦で優位、0.3 未満が続けば中央を奪えていない。`center_rate_none` との差が大きい場合は一方的な展開。 |
| `sefl_play/center_rate_team_b` | 0.0〜1.0（割合） | チームB（評価側）の中央占有率。 | A/B の差が 0.1 未満なら互角。B のみ高い場合は学習中モデルが中央を奪えていない。 |
| `sefl_play/death_turn_color1-4` | ターン数（整数） | 色ごとに「初めてその色の駒が 1 体落ちたターン」の平均。※通常は 1 駒喪失時点でログされる。 | 値が低いほど早死に。想定ロール順と実測がずれていれば役割分担の崩壊。突然の低下は環境変更やバグを疑う。ログ実装で複数駒条件になっていないか確認しておくと安心。 |
| `sefl_play/team_a_winrate` | 0.0〜1.0（勝率） | チームA（通常は最新ポリシー）の勝率。 | 0.5 超えは最新モデル優勢。0.7 以上で停滞するなら評価相手の弱さを疑う。0.5 未満が続くなら学習ハイパーや探索設定を見直す。 |
| `sefl_play/team_b_winrate` | 0.0〜1.0（勝率） | チームB（基準/旧モデル）の勝率。 | `team_a_winrate` と補完関係 (理想は `a + b = 1`)。合計が 1 から外れると集計・ロギング異常の可能性。 |

## 3. train 系（単バッチ指標）

| 指標名 | 単位・レンジ | 解釈 | 値の読み方 |
| --- | --- | --- | --- |
| `train/l2_loss` | 無次元・非負 | L2 正則化項（ウェイト減衰）。 | 急増は重みが肥大化しているサイン。0 に張り付けば正則化が効きすぎて学習が停滞している可能性。 |
| `train/policy_entropy` | nats（0〜logN） | ポリシー分布のエントロピー。 | 高いほど行動がランダム。学習序盤は高値、進むと緩やかに低下するのが理想。急低下は探索不足、急上昇はラベルのノイズ増加を示す。 |
| `train/policy_losss` | 無次元・非負 | ポリシーヘッドの損失（スペルミスのまま出力されるケース）。 | 下がるほどポリシー精度向上。上昇し続ける場合は学習率が高すぎるか、自己対局の品質が悪化している。 |
| `train/total_loss` | 無次元・非負 | 全損失（`policy + value + 正則化 + 補助項`）。 | 安定して下降→収束。発散→ハイパー調整。個別項目と併せ原因特定。 |
| `train/value_loss` | 無次元・非負 | 価値ヘッド（勝率/価値推定）の損失。 | プレイログの結果と一致しているかを確認。`policy_loss` だけ下がり `value_loss` が高止まりの場合、価値ラベル作成処理のバグを疑う。 |

## 4. train_avg 系（移動平均）

`train_avg/*` は上記 `train/*` の移動平均／指数平均。ノイズを除いたトレンド把握に使う。

| 指標名 | 単位・レンジ | 解釈 | 使い分け |
| --- | --- | --- | --- |
| `train_avg/l2_loss` | 無次元・非負 | L2 正則化の平均。 | 突発的なスパイクを平滑化し、モデルの複雑度傾向を追跡。 |
| `train_avg/policy_entropy` | nats（0〜logN） | 平均ポリシーエントロピー。 | 探索温度が徐々に下がっているかを確認。 |
| `train_avg/policy_loss` | 無次元・非負 | 平均ポリシー損失。 | 学習率変更や重みロードの効果を事後確認。 |
| `train_avg/total_loss` | 無次元・非負 | 平均総損失。 | 下降速度の鈍化で学習の行き詰まりを早期検知。 |
| `train_avg/value_loss` | 無次元・非負 | 平均価値損失。 | サンプルバッファ更新後の安定度を確認し、ラベル偏りがないかを見る。 |

---

### 実務での読み方 Tips

1. **自己対局 vs 価値損失**: `self_play/team_a_winrate` が改善しているのに `train/value_loss` が悪化する場合、価値ラベル生成や報酬設計の不一致を疑う。
2. **エントロピー監視**: `policy_entropy` が早期に低下した場合、探索温度・ノイズ追加・学習率減衰を調整しないと局所解に陥る。
3. **バッファ枯渇**: `buffer/size` が周期的にゼロ付近まで落ちると、データ供給が追い付いていない。サンプル収集を優先させる。

上記指標をセットで観察することで、単一メトリクスでは見抜けない異常（データ崩壊、探索不足、ハイパーずれ）を早期発見できます。
